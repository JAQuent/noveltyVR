---
title: "Selecting and checking living/non-living words"
author: "JÃ¶rn Alexander Quent"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: github_document
---

```{r setup, include=FALSE}
# Libraries
library(ggplot2)
library(knitr)
library(plyr)
library(gridExtra)
library(grid)
library(BayesFactor)
library(latex2exp)

# Settings
opts_knit$set(eval.after = 'fig.cap')
opts_chunk$set(echo = TRUE,
               warning = FALSE, 
               message = FALSE,
               fig.width = 10, 
               fig.height= 7)
options(scipen = 30)
```

# Aim
The aim of this document is selecting words for the project noveltyVR, in which we are planning to study the effect of novelty on words that were either weakly shallowly or strongly deeply encoded. In the shallow encoding condition, participants will have to decide whether the first and the last letter of a word are in alphabetical order as in Otten et al. (2001). In the deep encoding, participants need to decide whether something is animate/inanimate. A subset of words will be selected (kindly shared by Leun Otten), compared based on their properties found in the [MRC Psycholinguistic Database](http://websites.psychology.uwa.edu.au/school/MRCDatabase/uwa_mrc.htm) and finally split into three lists. 

# Counting words
Here, I count the number of words for each category (animancy, alphabetical) that are included in the file that was provided to me. 

```{r countingWords}
# Loading words used in https://academic.oup.com/brain/article/124/2/399/402300
words        <- read.table('U:/Projects/noveltyVR/preparation/ignore_wordlist_original_allcodes_fromOttten2001.txt', 
                           sep = '\t', 
                           header = TRUE)
names(words)  <- c('word', 'animacy', 'syllables', 'alphabetical')
words$word    <- as.character(words$word)
words$animacy <- factor(words$animacy, 
                       c(1, 0) ,
                       labels = c('animate', 'inanimate'))
words$alphabetical <- factor(words$alphabetical, 
                       c(1, 0) ,
                       labels = c('alphabetical', 'non-alphabetical'))

# How many words are there per category
table(words$animacy)
table(words$syllables)
table(words$alphabetical)
```


# Finding word properties
In the code below, I find the properties in the data base that are available for the words that I use. 

```{r}
# Calculating word length
words$wordLength  <- nchar(words$word)

# Loading MRC Psycholinguistic data base 
# See http://websites.psychology.uwa.edu.au/school/MRCDatabase/mrc2.html
mrcDatabase <- read.csv('U:/Projects/noveltyVR/preparation/ignoreFiles/WordStim/mrcOnly.txt', 
                        header = TRUE ,
                        fill = TRUE,
                        as.is = TRUE , 
                        na.strings = '', 
                        sep = '\t')

# MRC properties
words$K.F.FREQ   <- NA_real_
words$K.F.NCATS  <- NA_real_
words$K.F.NSAMP  <- NA_real_
words$T.L.FREQ   <- NA_real_
words$BROWN.FREQ <- NA_real_
words$FAM        <- NA_real_
words$CONC       <- NA_real_
words$IMAG       <- NA_real_
words$MEANC      <- NA_real_
words$MEANP      <- NA_real_
words$AOA        <- NA_real_
# Looking properties up in MRC database
for(i in 1:dim(words)[1]){
  words$K.F.FREQ[i]   <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'K.F.FREQ']
  words$K.F.NCATS [i] <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'K.F.NCATS']
  words$K.F.NSAMP[i]  <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'K.F.NSAMP']
  words$T.L.FREQ[i]   <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'T.L.FREQ']
  words$BROWN.FREQ[i] <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'BROWN.FREQ']
  words$FAM[i]        <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'FAM']
  words$CONC[i]       <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'CONC']
  words$IMAG[i]       <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'IMAG']
  words$MEANC[i]      <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'MEANC']
  words$MEANP[i]      <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'MEANP']
  words$AOA [i]       <- mrcDatabase[which(mrcDatabase$WORD == words[i, 1]),][1,'AOA']
}

# Replace any zero with NA
words[words == 0] <- NA_real_ 
```

# Split into four lists
Before splitting words into three lists, it is important find out how many words are animate and alphabetical, inanimate and alphabetical and so on in order to to select an equal number of words for all possible combinations. 

```{r}
combinations <- rep(1, dim(words)[1])
combinations[which(words$animacy == 'animate'   & words$alphabetical =='non-alphabetical')] <- 2
combinations[which(words$animacy == 'inanimate' & words$alphabetical =='alphabetical')]     <- 3
combinations[which(words$animacy == 'inanimate' & words$alphabetical =='non-alphabetical')] <- 4
words$combination <- combinations
table(words$combination)

# Words per list (max = min(table(words$combination)))
wordsPerCat <- 108 # There 110 inanimate/non-alphabetical words therefore we choose 108 because it's dividable by 3, which is important because we need three lists for shallow, deep and new words. Those two list again need to be dividedable by two, so they can be split in half to be assigned to the first and the second block of the ABBA design.
listlength <- (wordsPerCat/3)*4
```

Next, `r wordsPerCat` words are now randomly selected from each combination and then assigned a list. This number is chosen so that each list (`r listlength` words per list) can be further split in half but still having the same number for all possible combinations. 

```{r}
# Setting seed
set.seed(392)

# Selecting a random sample from each combination
comb1 <- words[sample(which(words$combination == 1), wordsPerCat),]
comb2 <- words[sample(which(words$combination == 2), wordsPerCat),]
comb3 <- words[sample(which(words$combination == 3), wordsPerCat),]
comb4 <- words[sample(which(words$combination == 4), wordsPerCat),]

# Shuffle order of comb
comb1 <- comb1[sample(1:wordsPerCat),]
comb2 <- comb2[sample(1:wordsPerCat),]
comb3 <- comb3[sample(1:wordsPerCat),]
comb4 <- comb4[sample(1:wordsPerCat),]

# Splitting into four lists
list1 <- rbind(comb1[1:(wordsPerCat/3),], 
               comb2[1:(wordsPerCat/3),],
               comb3[1:(wordsPerCat/3),],
               comb4[1:(wordsPerCat/3),])
list2 <- rbind(comb1[(wordsPerCat/3 + 1):(wordsPerCat/3*2),], 
               comb2[(wordsPerCat/3 + 1):(wordsPerCat/3*2),],
               comb3[(wordsPerCat/3 + 1):(wordsPerCat/3*2),],
               comb4[(wordsPerCat/3 + 1):(wordsPerCat/3*2),])
list3 <- rbind(comb1[(wordsPerCat/3*2 + 1):(wordsPerCat),], 
               comb2[(wordsPerCat/3*2 + 1):(wordsPerCat),],
               comb3[(wordsPerCat/3*2 + 1):(wordsPerCat),],
               comb4[(wordsPerCat/3*2 + 1):(wordsPerCat),])

# Concatenating lists again
wordsLists      <- rbind(list1, list2, list3)
wordsLists$list <- factor(rep(1:3, each = listlength))
```


# Inspecting properties of words in those lists
Below, I check whether any of the three lists differs on any of the relevant properties. A positive Bayes factor (BF) indicates evidence in favour of the hypothesis that the are no differences. 

Note that a lot of values in the database are 0, which are here treated as NA explaining the huge variability of the number of data points below. 

```{r inspectingWordlists, echo = FALSE}
# K.F.FREQ
bfTempData <- wordsLists[!is.na(wordsLists$K.F.FREQ),]
bfTemp     <- anovaBF(K.F.FREQ ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot1 <- ggplot(wordsLists, aes(x = list, y = K.F.FREQ)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$K.F.FREQ, na.rm = TRUE)*0.9, label = bfTemp)

# K.F.NCATS
bfTempData <- wordsLists[!is.na(wordsLists$K.F.NCATS),]
bfTemp     <- anovaBF(K.F.NCATS ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot2 <- ggplot(wordsLists, aes(x = list, y = K.F.NCATS)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$K.F.NCATS, na.rm = TRUE)*0.9, label = bfTemp)

# wordLength
bfTempData <- wordsLists[!is.na(wordsLists$wordLength),]
bfTemp     <- anovaBF(wordLength ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot3 <- ggplot(wordsLists, aes(x = list, y = wordLength)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$wordLength, na.rm = TRUE)*0.95, label = bfTemp)

# K.F.NSAMP
bfTempData <- wordsLists[!is.na(wordsLists$K.F.NSAMP),]
bfTemp     <- anovaBF(K.F.NSAMP ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot4 <- ggplot(wordsLists, aes(x = list, y = K.F.NSAMP)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$K.F.NSAMP, na.rm = TRUE)*0.9, label = bfTemp)

# T.L.FREQ
bfTempData <- wordsLists[!is.na(wordsLists$T.L.FREQ),]
bfTemp     <- anovaBF(T.L.FREQ ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot5 <- ggplot(wordsLists, aes(x = list, y = T.L.FREQ)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.4, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$T.L.FREQ, na.rm = TRUE)*0.9, label = bfTemp)

# BROWN.FREQ
bfTempData <- wordsLists[!is.na(wordsLists$BROWN.FREQ),]
bfTemp     <- anovaBF(BROWN.FREQ ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot6 <- ggplot(wordsLists, aes(x = list, y = BROWN.FREQ)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$BROWN.FREQ, na.rm = TRUE)*0.9, label = bfTemp)

# MEANP
bfTempData <- wordsLists[!is.na(wordsLists$MEANP),]
bfTemp     <- anovaBF(MEANP ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot7 <- ggplot(wordsLists, aes(x = list, y = MEANP)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$MEANP, na.rm = TRUE)*0.4, label = bfTemp)

# AOA
bfTempData <- wordsLists[!is.na(wordsLists$AOA),]
bfTemp     <- anovaBF(AOA ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot8 <- ggplot(wordsLists, aes(x = list, y = AOA)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$AOA, na.rm = TRUE)*0.92, label = bfTemp)

# FAM
bfTempData <- wordsLists[!is.na(wordsLists$FAM),]
bfTemp     <- anovaBF(FAM ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot9 <- ggplot(wordsLists, aes(x = list, y = FAM)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$FAM, na.rm = TRUE)*0.4, label = bfTemp)

# CONC
bfTempData <- wordsLists[!is.na(wordsLists$CONC),]
bfTemp     <- anovaBF(CONC ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot10 <- ggplot(wordsLists, aes(x = list, y = CONC)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$CONC, na.rm = TRUE)*0.4, label = bfTemp)

# MEANC
bfTempData <- wordsLists[!is.na(wordsLists$MEANC),]
bfTemp     <- anovaBF(MEANC ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot11 <- ggplot(wordsLists, aes(x = list, y = MEANC)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$MEANC, na.rm = TRUE)*0.4, label = bfTemp)

# IMAG
bfTempData <- wordsLists[!is.na(wordsLists$IMAG),]
bfTemp     <- anovaBF(IMAG ~ list, data = bfTempData, progress = FALSE)
bfTemp     <- TeX(paste('$BF_{01} = ', 
                        as.character(round(as.numeric(as.vector(1/bfTemp)), 3)), 
                        '$', 
                        sep = ''))

plot12 <- ggplot(wordsLists, aes(x = list, y = IMAG)) +
  geom_boxplot(alpha = 0.5, width = 0.4) +
  geom_jitter(width = 0.2, height = 0) +
  annotate('text', x = 2, y = max(bfTempData$IMAG, na.rm = TRUE)*0.4, label = bfTemp)

gridPlot <- grid.arrange(plot1,
                         plot2,
                         plot3,
                         plot4,
                         plot5,
                         plot6,
                         ncol = 2, 
                         nrow = 3)

gridPlot <- grid.arrange(plot7,
                         plot8,
                         plot9,
                         plot10,
                         plot11,
                         plot12,
                         ncol = 2, 
                         nrow = 3)
```

All Bayes factors above favour the hypothesis that there are no differences between the word lists. Therefore, we are going to use them in our experiment. 

Summary stats for all lists:

```{r creatingTable, echo = FALSE}
# Aggregating the mean, the SD and the number of words that have values for every metric
wordListsMetrics <- ddply(wordsLists, 
                          c('list'),
                          summarise,
                          wordLengthMean = mean(wordLength, na.rm = TRUE),
                          wordLengthSD   = sd(wordLength, na.rm = TRUE),
                          wordLengthN    = sum(!is.na(wordLength)),
                          K.F.FREQMean   = mean(K.F.FREQ, na.rm = TRUE),
                          K.F.FREQSD     = sd(K.F.FREQ, na.rm = TRUE),
                          K.F.FREQN      = sum(!is.na(K.F.FREQ)),
                          K.F.NCATSMean  = mean(K.F.NCATS, na.rm = TRUE),
                          K.F.NCATSSD    = sd(K.F.NCATS, na.rm = TRUE),
                          K.F.NCATSN     = sum(!is.na(K.F.NCATS)),
                          K.F.NSAMPMean  = mean(K.F.NSAMP, na.rm = TRUE),
                          K.F.NSAMPSD    = sd(K.F.NSAMP, na.rm = TRUE),
                          K.F.NSAMPN     = sum(!is.na(K.F.NSAMP)),
                          T.L.FREQMean   = mean(T.L.FREQ, na.rm = TRUE),
                          T.L.FREQSD     = sd(T.L.FREQ, na.rm = TRUE),
                          T.L.FREQN      = sum(!is.na(T.L.FREQ)),
                          BROWN.FREQMean = mean(BROWN.FREQ, na.rm = TRUE),
                          BROWN.FREQSD   = sd(BROWN.FREQ, na.rm = TRUE),
                          BROWN.FREQN    = sum(!is.na(BROWN.FREQ)),
                          FAMMean        = mean(FAM, na.rm = TRUE),
                          FAMSD          = sd(FAM, na.rm = TRUE),
                          FAMN           = sum(!is.na(FAM)),
                          CONCMean       = mean(CONC, na.rm = TRUE),
                          CONCSD         = sd(CONC, na.rm = TRUE),
                          CONCN          = sum(!is.na(CONC)),
                          IMAGMean       = mean(IMAG, na.rm = TRUE),
                          IMAGSD         = sd(IMAG, na.rm = TRUE),
                          IMAGN          = sum(!is.na(IMAG)),
                          MEANCMean      = mean(MEANC, na.rm = TRUE),
                          MEANCSD        = sd(MEANC, na.rm = TRUE),
                          MEANCN         = sum(!is.na(MEANC)),
                          MEANPMean      = mean(MEANP, na.rm = TRUE),
                          MEANPSD        = sd(MEANP, na.rm = TRUE),
                          MEANPN         = sum(!is.na(MEANP)),
                          AOAMean        = mean(AOA, na.rm = TRUE),
                          AOASD          = sd(AOA, na.rm = TRUE),
                          AOAN           = sum(!is.na(AOA)))

# I don't know a better way to do this
metrics <- c('Word length', 'K.F.FREQ', 'K.F.NCATS', 'K.F.NSAMP', 'T.L.FREQ','BROWN.FREQ', 
             'FAM', 'CONC', 'IMAG', 'MEANC', 'MEANP', 'AOA')
wordListsMetrics_t <- t(wordListsMetrics)
indexEnd           <- dim(wordListsMetrics_t)[1]
wordListsMetrics_t <- data.frame(Metric  = rep(metrics, each = 3), 
                                 List1   = as.numeric(wordListsMetrics_t[2:indexEnd,1]),
                                 List2   = as.numeric(wordListsMetrics_t[2:indexEnd,2]),
                                 List3   = as.numeric(wordListsMetrics_t[2:indexEnd,3]))

wordListsMetrics_table <- ddply(wordListsMetrics_t, 
                                c('Metric'),
                                summarise,
                                List1 = paste(round(List1[1], 2), ' (SD = ', round(List1[2], 2) ,')', sep = ''),
                                List2 = paste(round(List2[1], 2), ' (SD = ', round(List2[2], 2) ,')', sep = ''),
                                List3 = paste(round(List3[1], 2), ' (SD = ', round(List3[2], 2) ,')', sep = ''))

kable(wordListsMetrics_table)
```

## Writing text files
As all checks are completed without a problem, the input files for the task are created below.  

```{r writingFiles, eval = FALSE}
# Word list 1
write.table(subset(wordsLists, wordsLists$list == 1, select = c('word', 'animacy', 'alphabetical')),
          'wordList_1.txt',
          row.names = FALSE,
          col.names = FALSE,
          quote     = FALSE,
          sep       = ' ')

# Word list 2
write.table(subset(wordsLists, wordsLists$list == 2, select = c('word', 'animacy', 'alphabetical')),
          'wordList_2.txt',
          row.names = FALSE,
          col.names = FALSE,
          quote     = FALSE,
          sep       = ' ')

# Word list 3
write.table(subset(wordsLists, wordsLists$list == 3, select = c('word', 'animacy', 'alphabetical')),
          'wordList_3.txt',
          row.names = FALSE,
          col.names = FALSE,
          quote     = FALSE,
          sep       = ' ')
```


# References
Otten, L. J., Henson, R. N. A., & Rugg, M. D. (2001). Depth of processing effects on neural correlates of memory encoding: Relationship between findings from across- and within-task comparisons. Brain, 124(2), 399â412. https://doi.org/10.1093/brain/124.2.399