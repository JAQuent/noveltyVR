---
title: "Results of noveltyVR"
author: "Joern Alexander Quent"
date: "21/06/2021"
output:
  word_document: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

######################################################
# Path to parent folder noveltyVR
#path2parent <- "C:/Users/aq01/Documents/noveltyVR" # This need to be changed to run this document
path2parent <- "C:/Users/Alex/Documents/noveltyVR" # This need to be changed to run this document
######################################################
```


```{r}
library(plyr)
library(MPTinR)
library(matrixTests)
library(reshape2)
library(knitr)
library(chron)
library(ggplot2)
library(MRColour)
library(cowplot)
library(BayesFactor)
library(assortedRFunctions)
theme_set(theme_grey())

# Parameters
digits <- 3 # for signif/rounding
```


```{r load_data}
folderLocation  <- '/data/'
load(paste0(path2parent, folderLocation, 'noveltyVR_data_forSharing.RData'))

################################################# REMOVE ONCE PROPER DATA ##########################################7
recallSheet <- recallSheet[recallSheet$subNum != '7', ]

```


# Participants
```{r demographics}
n      <- nrow(demographics)
age    <- mean_SD_str2(demographics$age, 1, digits, 'signif', 'years')
gender <- table(demographics$gender)

# Time differences
t1 <- mean_SD_str2(times[times$group == 1, 'diff'], 1, digits, 'signif', 'hours')
t2 <- mean_SD_str2(times[times$group == 2, 'diff'], 1, digits, 'signif', 'hours')
```

A number of participants had to be replaced for the following reasons: One participant was replaced because of a coding error. Two participants did not complete the recognition task at all and another participant did not complete the recognition task in time (i.e. 40 hours after encoding). An additional participant's Pr was at chance level as defined the bootstrapping procedure. 

Furthermore for one participant, the recall data was lost and could not be retrieved. For another participant, the response on the VR questionnaire were not saved.  Due to human error, we collected 2 people more than necessary. 

The final sample size was therefore `r n` participants (`r gender[1]` females, `r gender[2]` males, `r gender[3]` non-binary) with mean age `r age`.  Participants in the novelty group completed the online recognition task `r t1` after encoding, while the control group completed the task after `r t2`. 

# Results
Note in the text we report original accuracy rates and probability estimates, while the statistical tests and effect size estimates we use arcsine transformed values.  

## Encoding task
```{r encoding_task_analysis}
############ RT
# Get values
val1 <- encodData_agg$rt[encodData_agg$task == 'living']
val2 <- encodData_agg$rt[encodData_agg$task == 'alphabetical']

# Only use data where both are not outliers
val1 <- val1[!(is.na(val1) | is.na(val2))]
val2 <- val2[!(is.na(val1) | is.na(val2))]

# Create report strings
str1 <- mean_SD_str2(val1, 1, digits, 'signif', 'msec')
str2 <- mean_SD_str2(val2, 1, digits, 'signif', 'msec')
d1   <- signif(mean(val2 - val1)/sd(val2 - val1), 3)

# Test
rtTest <- ttestBF(val1, 
                  val2, 
                  paired = TRUE)
rtTest <- reportBF(rtTest, digits, 'signif')

############ Accuracy
# Get values
val1 <- encodData_agg$acc[encodData_agg$task == 'living']
val2 <- encodData_agg$acc[encodData_agg$task == 'alphabetical']
wrong_keys1 <- sum(val1 == 0) 
wrong_keys2 <- sum(val2 == 0) 
wrong_keys  <- max(c(wrong_keys1, wrong_keys2))

# Only use data where both are not NA
includer <- !(is.na(val1) | val1 == 0 | is.na(val2) | val2 == 0)
val1 <- val1[includer]
val2 <- val2[includer]

# Create report strings
str3 <- mean_SD_str2(val1, 1, digits, 'signif')
str4 <- mean_SD_str2(val2, 1, digits, 'signif')

# Test on arcsine transformed 
val1 <- arcsine_transform(val1)
val2 <- arcsine_transform(val2)
d2   <- signif(mean(val2 - val1)/sd(val2 - val1), digits)

acTest <- ttestBF(val1,
                  val2, 
                  paired = TRUE)

acTest <- reportBF(1/acTest, digits, 'signif')
```

In the encoding task, `r numbers2words(wrong_keys)` participants did not use the correct keys so that these had to be exclude from the analysis. In this task, responses were faster in the animacy condition, `r str1`, compared to the alphabetical condition, `r str2`, $BF_{10}$ = `r as.character(rtTest)`, *d* = `r d1`. However, there was insufficient evidence whether accuracy in the animacy condition, `r str3`, was different from accuracy in the alphabetical condition, `r str4`, $BF_{01}$ = `r acTest`, *d* = `r d2`. 


```{r group_diff_encoding}
encoding_agg <- ddply(encodData, c('subNum', 'group'), summarise, RT = mean(RT, na.rm = TRUE), acc = mean(acc, na.rm = TRUE))

encoding_agg <- na.omit(encoding_agg)

#ttestBF(encoding_agg$RT[encoding_agg$group == 1], encoding_agg$RT[encoding_agg$group == 2])

#ttestBF(encoding_agg$acc[encoding_agg$group == 1], encoding_agg$acc[encoding_agg$group == 2])
```

## Memory tasks
```{r condition_table}
# Variables
conditions     <- 0:11
t1             <- 'alphabetical'
t2             <- 'living'
conditionTable <- data.frame(condition = conditions,
                             list1 = c(1, 1, 2, 2, 3, 3, 1, 1, 2, 2, 3, 3),
                             list2 = c(2, 3, 1, 3, 1, 2, 2, 3, 1, 3, 1, 2),
                             list3 = c(3, 2, 3, 1, 2, 1, 3, 2, 3, 1, 2, 1),
                             aTask = c(rep(t1, 6), rep(t2, 6)),
                             bTask = c(rep(t2, 6), rep(t1, 6)))

conditionTable$aTask <- as.character(conditionTable$aTask)
conditionTable$bTask <- as.character(conditionTable$bTask)

# Note that the col list1, list2 and list3 do not refer to the actual word lists wordList1.txt etc but only 
# to the 1st, 2nd and 3rd list. They col contains which actual wordList is assign to that spot. This might be confusing as in the recallSheet list1 etc refer to the wordLists
```

```{r results_table}
# Create dataframe
results <- data.frame(Hypothesis = c('1.1', '1.2', '2.1', '2.2', '3', '4'),
                       BF10 = rep(NA, 6),
                       BF01 = rep(NA, 6))
```

```{r mtp_analysis, include = FALSE}
# Split data into two each encoding task
recogData_alpha  <- subset(recogData, task == 'alphabetical' | task == 'unstudied')
recogData_living <- subset(recogData, task == 'living' | task == 'unstudied')

recogData_alpha_agg <- ddply(recogData_alpha, c('subNum', 'group', 'condition'),
                             summarise, 
                             studiedRemebered = sum(studied == 'studied'   & response == 'r'),
                             studiedFamiliar  = sum(studied == 'studied'   & response == 'f'),
                             studiedNew       = sum(studied == 'studied'   & response == 'n'),
                             newRemebered     = sum(studied == 'unstudied' & response == 'r'),
                             newFamiliar      = sum(studied == 'unstudied' & response == 'f'),
                             newNew           = sum(studied == 'unstudied' & response == 'n'))

fit_alpha            <- fit.mpt(recogData_alpha_agg[, 4:9], "MPT_RKN.model", n.optim = 50)
fit_alpha_individual <- fit_alpha$parameters$individual
fit_alpha_individual <- as.data.frame(t(fit_alpha_individual[,1,]))

recogData_living_agg <- ddply(recogData_living, c('subNum', 'group', 'condition'),
                              summarise,
                              studiedRemebered = sum(studied == 'studied'   & response == 'r'),
                              studiedFamiliar  = sum(studied == 'studied'   & response == 'f'),
                              studiedNew       = sum(studied == 'studied'   & response == 'n'),
                              newRemebered     = sum(studied == 'unstudied' & response == 'r'),
                              newFamiliar      = sum(studied == 'unstudied' & response == 'f'),
                              newNew           = sum(studied == 'unstudied' & response == 'n'))

fit_living            <- fit.mpt(recogData_living_agg[, 4:9], "MPT_RKN.model", n.optim = 50)
fit_living_individual <- fit_living$parameters$individual
fit_living_individual <- as.data.frame(t(fit_living_individual[,1,]))

participants <- unique(recogData$subNum)

row.names(fit_alpha_individual)  <- NULL
row.names(fit_living_individual) <- NULL

mainData_wide            <- rbind(fit_alpha_individual, fit_living_individual)
mainData_wide$subNum     <- rep(recogData_living_agg$subNum, 2)
mainData_wide$group      <- rep(recogData_living_agg$group, 2)
mainData_wide$encodTask  <- c(rep('alphabetical', length(participants)), rep('living', length(participants)))

# Reshape from wide to long
mainData <- melt(mainData_wide, id.vars = c("subNum", "group", "encodTask"))

# Exclude gr and gf
names(mainData)[4] <- 'parameter'
mainData           <- subset(mainData, parameter != 'gf' & parameter != 'gr')


# Make group factor
mainData$group <- factor(mainData$group, level = 1:2, labels = c('Novelty', 'Control'))

# Arcsine transformation
mainData$trans_value <- asin((mainData$value*2)-1)
```

```{r prepare_recall_data}
# Assign correct conditions to list 1, 2 and 3
recallData <- data.frame(subNum    = rep(recallSheet$subNum, each = 2),
                         group     = rep(recallSheet$group, each = 2),
                         condition = rep(recallSheet$condition, each = 2),
                         encodTask = rep(c('alphabetical', 'living'), dim(recallSheet)[1]),
                         recalled  = rep(NA_integer_,  dim(recallSheet)[1]*2))

# Loop through recallSheet
for(i in 1:dim(recallSheet)[1]){
  # Parse condition from conditionTable and save in tempCond
  tempCond <- conditionTable[which(recallSheet$condition[i] == conditionTable$condition), ]
  
  # Values from 1st and 2nd list
  val1 <- recallSheet[i, paste0('list', tempCond$list1)]
  val2 <- recallSheet[i, paste0('list', tempCond$list2)]
  
  # Assign to recallData according to the aTask
  if(tempCond$aTask == 'alphabetical'){
    recallData[recallData$subNum == recallSheet$subNum[i] & recallData$encodTask == 'alphabetical', 5] <- val1
    recallData[recallData$subNum == recallSheet$subNum[i] & recallData$encodTask == 'living', 5]       <- val2
  } else {
    recallData[recallData$subNum == recallSheet$subNum[i] & recallData$encodTask == 'alphabetical', 5] <- val2
    recallData[recallData$subNum == recallSheet$subNum[i] & recallData$encodTask == 'living', 5]       <- val1
  }
}
```


```{r hypothesis0}
#################### Recall
# Get values
val1 <- recallData$recalled[recallData$encodTask  == 'alphabetical']
val2 <- recallData$recalled[recallData$encodTask  == 'living']

# Create report strings
str1 <- mean_SD_str2(val1, 1, digits, 'signif')
str2 <- mean_SD_str2(val2, 1, digits, 'signif')
d1   <- signif(mean(val2 - val1)/sd(val2 - val1), digits)

# Test
test0.1 <- ttestBF(x = val1, y = val2)
test0.1 <- as.character(reportBF(test0.1, digits, 'signif'))

#################### Recognition
hypo0 <- ddply(mainData, c('subNum', 'encodTask'), summarise, value = mean(value), trans_value = mean(trans_value))

# Get values
val1 <- hypo0$value[hypo0$encodTask == 'alphabetical']
val2 <- hypo0$value[hypo0$encodTask == 'living']

# Create report strings
str3 <- mean_SD_str2(val1, 1, digits, 'signif')
str4 <- mean_SD_str2(val2, 1, digits, 'signif')

# Transform
val1 <- arcsine_transform(val1)
val2 <- arcsine_transform(val2)
d2   <- signif(mean(val2 - val1)/sd(val2 - val1), digits)

# Test
test0.2 <- ttestBF(x = val1, y = val2)
test0.2 <- as.character(reportBF(test0.2, digits, 'signif'))

```

Despite not explicitly registered in Stage 1, we also report the level of processing effect as it was the central manipulation with two-tailed tests. For recall, participants recalled more words in the animacy condition, `r str1`, than in the alphabetical condition, `r str2`, $BF_{10}$ = `r test0.1`, *d* = `r d1`. Similarly for the recognition, memory performance in the animacy condition, `r str3`, was better than in the alphabetical condition, `r str4`, $BF_{10}$ = `r test0.2`, *d* = `r d2`. We could therefore conclude with confidence that our level of processing manipulation was successful. 

```{r hypothesis1}
########### Recall
# Make factor
recallData$group <- factor(recallData$group, level = 1:2, labels = c('Novelty', 'Control'))

# Hypothesis 1.1
hypo1.1 <- ddply(recallData, c('subNum', 'group'), summarise, recalled = sum(recalled))

# Get values
val1 <- hypo1.1$recalled[hypo1.1$group == 'Novelty']
val2 <- hypo1.1$recalled[hypo1.1$group == 'Control']

# Create report strings
str1 <- mean_SD_str2(val1, 1, digits, 'signif')
str2 <- mean_SD_str2(val2, 1, digits, 'signif')
d1   <- signif(cohens_d_raw(val2, val1), digits)

# Test
test1.1 <- ttestBF(x = val1,
                   y = val2,
                   nullInterval = c(-Inf, 0))

results[1, 2] <- as.numeric(as.vector(test1.1[2]))
results[1, 3] <- 1/as.numeric(as.vector(test1.1[2]))

bf1 <- signif(results[1, 3], digits)

# Two-tailed test
test1.1_2tailed <- ttestBF(x = val1, y = val2)
bf2             <- reportBF(test1.1_2tailed, digits, 'signif')

########### Recognition
hypo1.2 <- ddply(mainData, c('subNum', 'group'), summarise, value = mean(value), trans_value = mean(trans_value))

# Get values
val1 <- hypo1.2$value[hypo1.2$group == 'Novelty']
val2 <- hypo1.2$value[hypo1.2$group == 'Control']

# Create report strings
str3 <- mean_SD_str2(val1, 1, digits, 'signif')
str4 <- mean_SD_str2(val2, 1, digits, 'signif')

# Transform
val1 <- arcsine_transform(val1)
val2 <- arcsine_transform(val2)
d2   <- signif(cohens_d_raw(val2, val1), digits)

# Test
test1.2 <- ttestBF(x = val1,
                   y = val2,
                   nullInterval = c(-Inf, 0))

results[2, 2] <- as.numeric(as.vector(test1.2[2]))
results[2, 3] <- 1/as.numeric(as.vector(test1.2[2]))
bf3           <- signif(results[2, 3] , digits)
```

In the following, we report the results of registered statistical tests of the influence of novelty on memory. For Hypothesis 1.1, we found that participants in the novelty group, `r str1` did not recall more words than participants in the control group, `r str2` with strong evidence against the null hypothesis, $BF_{01}$ = `r bf1`, *d* = `r d1`. Based on this we stopped data collection. In a two-tailed test (not registered), there was next to no evidence that the control group had better memory than the novelty group, $BF_{10}$ = `r bf2`. For Hypothesis 1.2, we found some evidence that the novelty group, `r str3`, did not have better memory than the control group, `r str4`, $BF_{01}$ = `r bf3`, *d* = `r d2`. 

For recognition, I also analysed Pr-values. 

```{r hypothesis1_Pr}
# Calculate hits and false alarms
recogData$hit <- ifelse(recogData$studied == 'studied' & (recogData$response == 'r' | recogData$response == 'f'), 1, 0)
recogData$fa  <- ifelse(recogData$studied == 'unstudied' & (recogData$response == 'r' | recogData$response == 'f'), 1, 0)

# Aggregate
agg_pr <- ddply(recogData, c('subNum', 'group', 'condition'), summarise, pHit = sum(hit)/288, pFA = sum(fa/144))
agg_pr$pr <- agg_pr$pHit - agg_pr$pFA

# Get values
val1 <- agg_pr$pr[agg_pr$group == 1]
val2 <- agg_pr$pr[agg_pr$group == 2]

# Create report strings
str3 <- mean_SD_str2(val1, 1, digits, 'signif')
str4 <- mean_SD_str2(val2, 1, digits, 'signif')
d2   <- signif(cohens_d_raw(val2, val1), digits)


# Test
test1.2 <- ttestBF(x = val1,
                   y = val2,
                   nullInterval = c(-Inf, 0))

results[2, 2] <- as.numeric(as.vector(test1.2[2]))
results[2, 3] <- 1/as.numeric(as.vector(test1.2[2]))
bf3           <- signif(results[2, 3] , digits)
```

For Hypothesis 1.2, we found some evidence that the novelty group, `r str3`, did not have better memory than the control group, `r str4`, $BF_{01}$ = `r bf3`, *d* = `r d2`. 


```{r hypothesis2}
# Hypothesis 2.1
hypo2.1 <- recallData
diff2.1.1 <- hypo2.1[hypo2.1$group == 'Control' & hypo2.1$encodTask == 'living', 'recalled'] - 
             hypo2.1[hypo2.1$group == 'Control' & hypo2.1$encodTask == 'alphabetical', 'recalled']

diff2.1.2 <- hypo2.1[hypo2.1$group == 'Novelty' & hypo2.1$encodTask == 'living', 'recalled'] - 
             hypo2.1[hypo2.1$group == 'Novelty' & hypo2.1$encodTask == 'alphabetical', 'recalled']

# Get values
val1 <- diff2.1.1
val2 <- diff2.1.2

# Create report strings
str1 <- mean_SD_str2(val1, 1, digits, 'signif')
str2 <- mean_SD_str2(val2, 1, digits, 'signif')
d1   <- signif(cohens_d_raw(val1, val2), digits)

test2.1   <- ttestBF(x = val1,
                     y = val2,
                     nullInterval = c(-Inf, 0))


results[3, 2] <- as.numeric(as.vector(test2.1[2]))
results[3, 3] <- 1/as.numeric(as.vector(test2.1[2]))
bf1           <- signif(results[3, 2], digits)

# Hypothesis 2.2
hypo2.2 <- ddply(mainData, c('subNum', 'group', 'encodTask'), summarise , value = mean(value), trans_value = mean(trans_value))
diff2.2.1_val <- hypo2.2[hypo2.2$group == 'Control' & hypo2.2$encodTask == 'living', 'value'] - 
                 hypo2.2[hypo2.2$group == 'Control' & hypo2.2$encodTask == 'alphabetical', 'value']

diff2.2.2_val <- hypo2.2[hypo2.2$group == 'Novelty' & hypo2.2$encodTask == 'living', 'value'] - 
                 hypo2.2[hypo2.2$group == 'Novelty' & hypo2.2$encodTask == 'alphabetical', 'value']

diff2.2.1_trans_val <- hypo2.2[hypo2.2$group == 'Control' & hypo2.2$encodTask == 'living', 'trans_value'] - 
                       hypo2.2[hypo2.2$group == 'Control' & hypo2.2$encodTask == 'alphabetical', 'trans_value']

diff2.2.2_trans_val <- hypo2.2[hypo2.2$group == 'Novelty' & hypo2.2$encodTask == 'living', 'trans_value'] - 
                       hypo2.2[hypo2.2$group == 'Novelty' & hypo2.2$encodTask == 'alphabetical', 'trans_value']


# Get values
val1 <- diff2.2.1_val
val2 <- diff2.2.2_val

# Create report strings
str3 <- mean_SD_str2(val1, 1, digits, 'signif')
str4 <- mean_SD_str2(val2, 1, digits, 'signif')
d2   <- signif(cohens_d_raw(val1, val2), digits)

test2.2   <- ttestBF(x = diff2.2.1_trans_val,
                     y = diff2.2.2_trans_val,
                     nullInterval = c(-Inf, 0))

results[4, 2] <- as.numeric(as.vector(test2.2[2]))
results[4, 3] <- 1/as.numeric(as.vector(test2.2[2]))
bf2           <- signif(results[4, 2], digits)

```

For Hypothesis 2, we found the number of words recalled in the animacy condition minus the number of words recalled in the alphabetical condition does not reliably differ between the novelty group, `r str2`, and the control group, `r str1`, $BF_{10}$ = `r bf1`, *d* = `r d1` (Hypothesis 2.1). The same is true for the same comparison between the novelty group,`r str4`, and the control group, `r str3`, with averaged recognition estimates that also did not allow to draw any conclusion, $BF_{10}$ = `r bf2`, *d* = `r d2` (Hypothesis 2.2). 

For recognition, I also analysed Pr-values. 
```{r hypothesis2_Pr}
# Hypothesis 2
# Calculate Pr for alphabetical task (so not living)
agg_pr_alpha    <- ddply(recogData[recogData$task != 'living',], c('subNum', 'group', 'condition'), summarise, pHit = sum(hit)/144, pFA = sum(fa/144))
agg_pr_alpha$pr <- agg_pr_alpha$pHit - agg_pr_alpha$pFA

# Calculate Pr for living task (so not alphabetical)
agg_pr_living    <- ddply(recogData[recogData$task != 'alphabetical',], c('subNum', 'group', 'condition'), summarise, pHit = sum(hit)/144, pFA = sum(fa/144))
agg_pr_living$pr <- agg_pr_living$pHit - agg_pr_living$pFA


diff2.2.1_val <- agg_pr_living[agg_pr_living$group == 2, 'pr'] - agg_pr_alpha[agg_pr_alpha$group == 2, 'pr'] 

diff2.2.2_val <- agg_pr_living[agg_pr_living$group == 1, 'pr'] - agg_pr_alpha[agg_pr_alpha$group == 1, 'pr'] 

# Get values
val1 <- diff2.2.1_val
val2 <- diff2.2.2_val

# Create report strings
str3 <- mean_SD_str2(val1, 1, digits, 'signif')
str4 <- mean_SD_str2(val2, 1, digits, 'signif')
d2   <- signif(cohens_d_raw(val1, val2), digits)

test2.2   <- ttestBF(x = diff2.2.1_val,
                     y = diff2.2.2_val,
                     nullInterval = c(-Inf, 0))

results[4, 2] <- as.numeric(as.vector(test2.2[2]))
results[4, 3] <- 1/as.numeric(as.vector(test2.2[2]))
bf2           <- signif(results[4, 2], digits)
```

The same is true for the same comparison between the novelty group,`r str4`, and the control group, `r str3`, with Pr that also did not allow to draw any conclusion, $BF_{10}$ = `r bf2`, *d* = `r d2` (Hypothesis 2.2). 

```{r hypothesis3}
# Hypothesis 3
hypo3 <- ddply(mainData, c('subNum', 'group', 'parameter'), summarise, value = mean(value), trans_value = mean(trans_value))
diff3.1     <- hypo3[hypo3$group == 'Control' & hypo3$parameter == 'r', 'trans_value'] - 
               hypo3[hypo3$group == 'Control' & hypo3$parameter == 'f', 'trans_value']
diff3.2     <- hypo3[hypo3$group == 'Novelty' & hypo3$parameter == 'r', 'trans_value'] - 
               hypo3[hypo3$group == 'Novelty' & hypo3$parameter == 'f', 'trans_value']

# Get values
val1     <- hypo3[hypo3$group == 'Control' & hypo3$parameter == 'r', 'value'] - 
            hypo3[hypo3$group == 'Control' & hypo3$parameter == 'f', 'value']
val2     <- hypo3[hypo3$group == 'Novelty' & hypo3$parameter == 'r', 'value'] - 
            hypo3[hypo3$group == 'Novelty' & hypo3$parameter == 'f', 'value']


# Create report strings
str1 <- mean_SD_str2(val1, 1, digits, 'signif')
str2 <- mean_SD_str2(val2, 1, digits, 'signif')
d1   <- signif(cohens_d_raw(diff3.1, diff3.2), digits)

test3     <- ttestBF(x = diff3.1,
                     y = diff3.2)

results[5, 2] <- as.numeric(as.vector(test3))
results[5, 3] <- 1/as.numeric(as.vector(test3))
bf1           <- signif(results[5, 2], digits)
```

Regarding Hypothesis 3 (two-tailed), we found that the difference between recognition parameters (r - f) between the novelty group, `r str2` , and the control group, `r str1`, was not conclusive $BF_{10}$ = `r bf1`, *d* = `r d1`. 

```{r hypothesis4}
# Hypothesis 4
hypo4 <- mainData

row.names(mainData) <- as.character(1:dim(mainData)[1])
# (E1M1 – E2M1)
diff4.1 <- mainData[mainData$group == 'Control' & mainData$encodTask == 'living' & mainData$parameter == 'f', 'trans_value'] - 
           mainData[mainData$group == 'Control' & mainData$encodTask == 'alphabetical' & mainData$parameter == 'f', 'trans_value']
# (E1M2 – E2M2)
diff4.2 <- mainData[mainData$group == 'Control' & mainData$encodTask == 'living' & mainData$parameter == 'r', 'trans_value'] - 
           mainData[mainData$group == 'Control' & mainData$encodTask == 'alphabetical' & mainData$parameter == 'r', 'trans_value']

# Difference of differences (E1M1 – E2M1) – (E1M2 – E2M2)
diff4.3     <- diff4.1 - diff4.2

# Group 2
# (E1M1 – E2M1)
diff4.4 <- mainData[mainData$group == 'Novelty' & mainData$encodTask =='living' & mainData$parameter == 'f', 'trans_value'] - 
           mainData[mainData$group == 'Novelty' & mainData$encodTask == 'alphabetical' & mainData$parameter == 'f', 'trans_value']
# (E1M2 – E2M2)
diff4.5 <- mainData[mainData$group == 'Novelty' & mainData$encodTask == 'living' & mainData$parameter == 'r', 'trans_value'] - 
           mainData[mainData$group == 'Novelty' & mainData$encodTask == 'alphabetical' & mainData$parameter == 'r', 'trans_value']

# Difference of differences (E1M1 – E2M1) – (E1M2 – E2M2)
diff4.7     <- diff4.4 - diff4.5

# Test
test4     <- ttestBF(x = diff4.3,
                     y = diff4.7)

d1   <- signif(cohens_d_raw(diff4.7, diff4.3), digits)

results[6, 2] <- as.numeric(as.vector(test4))
results[6, 3] <- 1/as.numeric(as.vector(test4))
bf1 <-  signif(results[6, 2], digits)

# (E1M1 – E2M1)
diff4.1 <- mainData[mainData$group == 'Control' & mainData$encodTask == 'living' & mainData$parameter == 'f', 'value'] - 
           mainData[mainData$group == 'Control' & mainData$encodTask == 'alphabetical' & mainData$parameter == 'f', 'value']
# (E1M2 – E2M2)
diff4.2 <- mainData[mainData$group == 'Control' & mainData$encodTask == 'living' & mainData$parameter == 'r', 'value'] - 
           mainData[mainData$group == 'Control' & mainData$encodTask == 'alphabetical' & mainData$parameter == 'r', 'value']

# Difference of differences (E1M1 – E2M1) – (E1M2 – E2M2)
diff4.3     <- diff4.1 - diff4.2

# Group 2
# (E1M1 – E2M1)
diff4.4 <- mainData[mainData$group == 'Novelty' & mainData$encodTask =='living' & mainData$parameter == 'f', 'value'] - 
           mainData[mainData$group == 'Novelty' & mainData$encodTask == 'alphabetical' & mainData$parameter == 'f', 'value']
# (E1M2 – E2M2)
diff4.5 <- mainData[mainData$group == 'Novelty' & mainData$encodTask == 'living' & mainData$parameter == 'r', 'value'] - 
           mainData[mainData$group == 'Novelty' & mainData$encodTask == 'alphabetical' & mainData$parameter == 'r', 'value']

# Difference of differences (E1M1 – E2M1) – (E1M2 – E2M2)
diff4.7     <- diff4.4 - diff4.5

str1 <- mean_SD_str2(diff4.3, 1, digits, 'signif')
str2 <- mean_SD_str2(diff4.7, 1, digits, 'signif')
```

To test for the interaction of Hypothesis 4, we first calculated the difference between the two encoding conditions (animacy & alphabetical) for each group and for each parameter (r & f). We then calculated the difference of the condition difference (animacy & alphabetical) by substracting f - r and subjected these difference scores for the novelty group,`r str2`, and the control group, `r str1`, to statistical test, $BF_{10}$ = `r bf1`, *d* = `r d1`. 


Table X: A summary of the results of the four primary hypothesis
```{r summary_table}
# Round
results$BF10 <- signif(results$BF10, digits)
results$BF01 <- signif(results$BF01, digits)

# Display table
kable(results)
```

All in all, we have been unable to provide any evidence in favour of our hypotheses. 

## Post VR questionnaire

Table X: Summary of the results comparing the ratings for each post VR question with two-tailed tests. 
```{r question_table}
# Fix error of NA as rowname
names_quest <- names(questData)
names_quest[which(is.na(names_quest))] <- 'group1'
names(questData) <- names_quest

quests <- unique(questData$question)
nQuest <- length(quests)

bf10s  <- c()



for(i in 1:nQuest){
  temp1 <- questData[questData$question == quests[i] & questData$group == 'Novelty', 'rating']
  temp2 <- questData[questData$question == quests[i] & questData$group == 'Control', 'rating']
  bf10s[i] <- reportBF(ttestBF(temp1, temp2, paired = FALSE), digits, 'signif')
}

quest_results <- data.frame(Question = quests, BF10 = bf10s)
quest_results$BF01 <- signif(1/quest_results$BF10, 3)
kable(quest_results)

# Report values
val1 <- questData[questData$shortcut == 'novelty' & questData$group == 'Novelty', 'rating']
val2 <- questData[questData$shortcut == 'novelty' & questData$group == 'Control', 'rating']

str1 <- mean_SD_str2(val1, 1, digits, 'signif')
str2 <- mean_SD_str2(val2, 1, digits, 'signif')
d1   <- signif(cohens_d_raw(val1, val2), digits)
```

As can be seen in Table X, none of the questions showed a reliable group difference. The fact that participants in the novelty group,`r str1` , did not rate their experience as more novel as the participants in the control group, `r str2` , $BF_{10}$ = `r quest_results[15, 2]`, *d* = `r d1` is noteworthy here. 


```{r ipq_analysis}
# Recode so that scale goes from 0 to 6 like the original 
questData$trans_rating <- (questData$rating + 100)*0.03

# Change reverse coding of sp2, inv3  & real1
# SP2
questData$trans_rating[questData$itemName == 'SP2']   <- -1*questData$trans_rating[questData$itemName == 'SP2'] + 6
# INV3
questData$trans_rating[questData$itemName == 'INV3']  <- -1*questData$trans_rating[questData$itemName == 'INV3'] + 6
# REAL1
questData$trans_rating[questData$itemName == 'REAL1'] <- -1*questData$trans_rating[questData$itemName == 'REAL1'] + 6


# Only IPQ
ipq        <- questData[questData$copyright != 'noveltyVR',]
ipq_scores <- ddply(ipq, c('subNum', 'group'), summarise, score = sum(trans_rating))


sp_only       <- ipq[ipq$itemName %in% paste0('SP', 1:5), ]
sp_ony_scores <- ddply(sp_only, c('subNum', 'group'), summarise, score = sum(trans_rating))

# Quest1: 
quest1 <- "This experience was novel."
quest1_only <-  questData[questData$question == quest1,]

# Quest2:
quest2 <- "This experience was exciting."
quest2_only <-  questData[questData$question == quest2,]

# Quest3: 
quest3 <- "This experiences was uncomfortable."
quest3_only <-  questData[questData$question == quest3,]
```

```{r quest_tests}
# IPQ
# Report values
val1 <- ipq_scores[ipq_scores$group == 'Novelty', 'score']
val2 <- ipq_scores[ipq_scores$group == 'Control', 'score']

str1 <- mean_SD_str2(val1, 1, digits, 'signif')
str2 <- mean_SD_str2(val2, 1, digits, 'signif')
d1   <- signif(cohens_d_raw(val2, val1), digits)

bf1  <- reportBF(ttestBF(x = val1, y = val2), digits, 'signif')

# Quest 1
# Report values
val1 <- quest1_only[quest1_only$group == 'Novelty', 'trans_rating']
val2 <- quest1_only[quest1_only$group == 'Control', 'trans_rating']

str3 <- mean_SD_str2(val1, 1, digits, 'signif')
str4 <- mean_SD_str2(val2, 1, digits, 'signif')

# Deal with negative skew by using arcsine transformation
val1 <- arcsine_transform(val1/6)
val2 <- arcsine_transform(val2/6)

d2   <- signif(cohens_d_raw(val1, val2), digits)
bf2  <- reportBF(ttestBF(x = val1, y = val2), digits, 'signif')

```


As an additional non-registered analysis, we examined the data from post VR questionnaire that we collected. For this, the data was rescaled to vary from 0 to 6 like the original scale (see Schubert et al., 2001) and items that were inversely scaled reversed. The IPQ score was then calculated by summing across all items. This analysis showed that the novelty group, `r str1` , did not differ from the control group, `r str2`, *d* = `r d1`, BF10 = `r bf1`. In addition, we asked participants to rate the questions: "This experience was novel", "This experience was exciting" and "This experience was uncomfortable", however group differences did not arise for any of these statements. Especially for statement 1, the novelty group rated their experience, `r str3`, and the control group rated theirs, `r str4`, *d* = `r d2`, BF10 = `r bf2`.